{
 "metadata": {
  "name": "IBCF from scratch"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implementation of Item-based Collaborative Filtering as described in http://cran.r-project.org/web/packages/recommenderlab/vignettes/recommenderlab.pdf."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from random import shuffle\n",
      "import csv\n",
      "\n",
      "# \"matrix\" of user views of the form\n",
      "# {user_id:{item_id: preference, item_id2: preference, ...}, user_id2: {...}, ...}\n",
      "train_data = defaultdict(dict)\n",
      "test_data = defaultdict(dict)\n",
      "\n",
      "# The transpose of train_data, makes cosine similarity much easier/faster\n",
      "item_data = defaultdict(dict)\n",
      "\n",
      "all_articles = set()\n",
      "all_users = set()\n",
      "\n",
      "# map from article id's to the total number of views\n",
      "article_popularity = defaultdict(int)\n",
      "\n",
      "# Populate from files\n",
      "with open('part-r-00000', 'rb') as csvfile:\n",
      "    reader = csv.reader(csvfile)\n",
      "    for user_id, article_id, _ in reader: \n",
      "        train_data[user_id][article_id] = 1\n",
      "        \n",
      "        # test data includes all of the past train data\n",
      "        test_data[user_id][article_id] = 1\n",
      "        \n",
      "        item_data[article_id][user_id] = 1\n",
      "        \n",
      "        all_users.add(user_id)\n",
      "        all_articles.add(article_id)\n",
      "        \n",
      "        article_popularity[article_id] += 1\n",
      "\n",
      "with open('part-m-00000', 'rb') as csvfile:\n",
      "    reader = csv.reader(csvfile)\n",
      "    for user_id, article_id in reader:\n",
      "        test_data[user_id][article_id] = 1\n",
      "        \n",
      "        all_users.add(user_id)\n",
      "        all_articles.add(article_id)\n",
      "        \n",
      "        article_popularity[article_id] += 1\n",
      "        \n",
      "all_articles = list(all_articles)\n",
      "all_users = list(all_users)\n",
      "\n",
      "# reduce the size of test and train data\n",
      "# for some stupid reason shuffle mutates the list in place and returns None\n",
      "shuffle(all_users)\n",
      "# shuffle(all_articles)\n",
      "\n",
      "# here we sort the articles in decreasing popularity \n",
      "# so that we select the most popular articles\n",
      "all_articles.sort(key=lambda article_id: -1.0 * article_popularity[article_id])\n",
      "\n",
      "# list of a subset of article id's\n",
      "#lil_articles = all_articles[:500]\n",
      "\n",
      "#lil_users = all_users[:5000]\n",
      "\n",
      "lil_articles = all_articles\n",
      "lil_users = all_users\n",
      "\n",
      "# hardcore data chopping kung fu here\n",
      "train_data = {user_id: {item_id: val for item_id, val in train_data[user_id].iteritems() \\\n",
      "                                     if item_id in lil_articles} \\\n",
      "                 for user_id in lil_users}\n",
      "test_data = {user_id: {item_id: val for item_id, val in test_data[user_id].iteritems() \\\n",
      "                                     if item_id in lil_articles} \\\n",
      "                 for user_id in lil_users}\n",
      "\n",
      "print 'len(train_data)', 'len(test_data)', 'len(lil_articles)'\n",
      "print len(train_data), len(test_data), len(lil_articles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "len(train_data) len(test_data) len(lil_articles)\n",
        "26670 26670 9821\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cosine_similarity(item1, item2):\n",
      "    \"\"\"item1 and item2 should be \"rows\" of item_data of the form {user_id: 1, ...}\n",
      "       We make the assumption that all values of the dicts are 1.\n",
      "    \"\"\"\n",
      "    from math import sqrt\n",
      "    a = set(item1.keys())\n",
      "    b = set(item2.keys())\n",
      "    if sqrt(len(a)) * sqrt(len(b)) == 0:\n",
      "        return 0\n",
      "    return 1.0 * len(a & b) / (sqrt(len(a)) * sqrt(len(b)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def jaccard_similarity(item1, item2):\n",
      "    \"\"\"See page 6\"\"\"\n",
      "    a = set(item1.keys())\n",
      "    b = set(item2.keys())\n",
      "    return 1.0 * len(a & b) / len(a | b) if len(a | b) > 0 else 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# associations between user and article id's and their row and column positions in the matrix\n",
      "\n",
      "row_by_user_id = dict(zip(lil_users, xrange(len(lil_users))))\n",
      "user_id_by_row = dict(zip(xrange(len(lil_users)), lil_users))\n",
      "\n",
      "col_by_item_id = dict(zip(lil_articles, xrange(len(lil_articles))))\n",
      "item_id_by_col = dict(zip(xrange(len(lil_articles)), lil_articles))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build similarity matrix S\n",
      "from scipy.sparse import lil_matrix\n",
      "S = lil_matrix((len(lil_articles), len(lil_articles)))\n",
      "print S.shape\n",
      "\n",
      "# Unfortunately, this is O(n^2*m) because the similarity check is O(m)\n",
      "# but there's not much we can do about it\n",
      "\n",
      "k = 5\n",
      "sims = {}\n",
      "\n",
      "i = 0\n",
      "for item_id1 in lil_articles:\n",
      "    i += 1\n",
      "    if i % 50 == 0: print i\n",
      "    \n",
      "    for item_id2 in lil_articles:\n",
      "        sim = jaccard_similarity(item_data[item_id1], \\\n",
      "                                 item_data[item_id2])\n",
      "        if sim > 0:\n",
      "#            print col_by_item_id[item_id1], col_by_item_id[item_id2], sim\n",
      "            S[col_by_item_id[item_id1], col_by_item_id[item_id2]] = sim\n",
      "            S[col_by_item_id[item_id2], col_by_item_id[item_id1]] = sim\n",
      "        \n",
      "    # Find top k most similar and put in sims\n",
      "    rowvec = S.getrow(col_by_item_id[item_id1]).todense().tolist()[0]\n",
      "    \n",
      "    # ignore the current item\n",
      "    rowvec[col_by_item_id[item_id1]] = nan\n",
      "    \n",
      "    # filter out 0's\n",
      "    stuff = [x for x in zip(lil_articles, rowvec) if x[1] > 0]\n",
      "    \n",
      "    sims[item_id1] = [x[0] for x in sorted(stuff, key=lambda x: -1.0 * x[1])[:k]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_rating(u, i):\n",
      "    \"\"\"u - the user id\n",
      "       i - the item id\n",
      "    \"\"\"\n",
      "    a = 0\n",
      "    b = 0\n",
      "    for j in sims[i]:\n",
      "        r_uj = test_data[u][j] if j in test_data[u] else 0\n",
      "        a += S[col_by_item_id[i], col_by_item_id[j]] * r_uj\n",
      "        b += S[col_by_item_id[i], col_by_item_id[j]]\n",
      "        \n",
      "#    return a / S.getrow(col_by_item_id[i]).sum()\n",
      "    return 1.0 * a / b if b > 0 else 0\n",
      "\n",
      "def predict_all_ratings(u):\n",
      "    \"\"\"u - the user id\"\"\"\n",
      "    return map(lambda i: (i, predict_rating(u, i)), lil_articles)\n",
      "\n",
      "def recommend(u, how_many):\n",
      "    # better yet do this in linear time to the number of articles\n",
      "    pred_ratings = predict_all_ratings(u)\n",
      "    return sorted([x for x in pred_ratings if x[1] > 0], key=lambda x: -1 * x[1])[:how_many]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build confusion matrix\n",
      "a, b, c, d = 0, 0, 0, 0\n",
      "how_many = 10\n",
      "i = 0\n",
      "for user_id, prefs in test_data.iteritems():\n",
      "    i += 1\n",
      "    if i % 50 == 0: print i\n",
      "        \n",
      "    actual_read = set(prefs.keys())\n",
      "    actual_notread = set(lil_articles) - actual_read\n",
      "    \n",
      "    predicted_read = set([rec[0] for rec in recommend(user_id, how_many)])\n",
      "    predicted_notread = set(lil_articles) - predicted_read\n",
      "    \n",
      "    a += len(actual_notread & predicted_notread)\n",
      "    b += len(actual_notread & predicted_read)\n",
      "    c += len(actual_read & predicted_notread)\n",
      "    d += len(actual_read & predicted_read)\n",
      "    \n",
      "print a, b, c, d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precision = 1.0 * d / (b + d)\n",
      "recall = 1.0 * d / (c + d)\n",
      "F1 = 2 * precision * recall / (precision + recall)\n",
      "\n",
      "print 'precision', 'recall', 'F1'\n",
      "print precision, recall, F1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}